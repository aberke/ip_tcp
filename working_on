THINGS NEIL WANTS ALEX TO USE

bin/find thing 

printf("hello %d", num)
print( ("hello %d", num), TCP_PRINT)

STDIN thread
where we lock:  we lock in the tcp_api_function_entry thread call after we call 
				tcp_node_get_connection_by_socket and check connection not null
where we unlock: in tcp_api_args_destroy

linked_list<thread> threads;
while(1){
	
	select(STDIN, .01 seconds);
	command = get_command(input);
	if(command == "accept"){
		tcp_node_accept(command_line, node);
	}
	
	whenever you call a blocking call (api call)
	thread = new thread()
	thread.call(blocking_call)
	threads.append(thread);

	for each thread_waiting:
		int result;
		try:
			thread.join(thread, &result);
		except:	

		if thread is done
			do something with result
			threads.remove(thread)

}

functions written by 

void tcp_connection_api_signal(tcp_connection_t connection);
void tcp_connection_api_lock(tcp_connection_t connection);
void tcp_connection_api_unlock(tcp_connection_t connection);
void tcp_connection_api_wait(tcp_connection_t connection);

I'll also write the mutex for the send window

give to tcp_connection:

	tcp_connection	
		int ret_value; // return value for the calling tcp_api function
		pthread_mutex_t api_mutex
		pthread_cond_t api_cond
		// now when a tcp_api function calls, it will lock the mutex, and wait on the api_cond for the 
		//tcp connection to finish its duties
		
// calls pthread_cond_signal(api_cond) so that the waiting tcp_api function can stop waiting and take a look at the 
// return value		
tcp_connection_api_signal(connection); 


Thread-heavy solution

TCP_NODE
-----------------------------

has array of connections
hashmap: virt_socketToConnection
hashmap: portToConnection

when demultiplexes a packet calls 
	connection = portToConnection(port)
	tcp_connection_queue_to_read(connection, packet)
	
	each tcp_connection runs a thread to handle packets on to_read

threads will be handled within the TCP_CONNECTION itself and will not
be known about anywhere


TCP_CONNECTION
------------------------------
#include <sys/time.h>




int syn_count=0;
time_t connect_accept_timer;

time_t now;

runs the following thread:

while(tcp_connection->running){
	bqueue_dequeue(my to_read, .001);

	gettimeofday(&now, NULL);
	if(syn_sent){	
		if(difftime(now, connect_accept_timer) > 2**syn_count * SYN_TIMEOUT){
			resend (my syn);
			my syn ++;
		}
	}
	if(established){
		check_timers(my to_send);
		chunk_t chunk;
		while(chunk = get_next(my to_send)){
			send(chunk);
		}
	}
}


LISTEN TO SYN_RECEIVED:
	so when we receive a syn we need to create a new connection!  It is that connection that must set the 
		seq_num in the received packet as its last_seq_received
	here's how I think we should go about it:
		design challenge: the listening connection doesn't have a way to insert a new connection in the node's kernal
			also, when we receive syn, in order for the newly created connection to synchronize, it needs to be the 
				NEW connection that sets this syn as last_syn_received.
			
		Alex's Solution: 
		
			I do think that the tcp_connection needs to know about the node.
				because a tcp_connection in LISTEN state that receives a syn needs to create a new connection with
				a unique port so that the rest of the correspondance when this connection can be multiplex appropriately by node
				BUT only node knows about the next available port
				(this also means that when we destroy connections we can alert node that the socket and port
					of that connection is again available for reuse)
		
			We need to go about this slightly differently (sorry not a pretty use of state machine)
			
			instead of changing state we need to verify that the receiving connection is in LISTEN state.
			if in LISTEN state:
				node 
		
		my idea for solution:
			when syn received, we'll change state as usual
			in tcp_connection_LISTEN_to_SYN_RECEIVED:
				connection in LISTEN state will stay in LISTEN state and create a new



NEIL:
state_machine -- done
window        -- struct that implements a very abstract, high-level version of the sliding window protocol -- almost done
					-- please make some default init args

##HAS TODO ITEM INSIDE## -- Trying to use as flag inside header files to indicate that a function still has TODO items inside
								-- WE NEED TO DO THEM!

NOTE: to_read and to_send queues only queue tcp_packet_data_t's  -- stick by this convention!

			
	We should think about what having only one ip_node means for the sliding window protocol (if only want one ip_node).

	tcp_node owns the following table:
		_________________________________ __ __ __
		int socket_id		| 	| 	|	|				<-- exactly what socket_api passes back when call socket(), accept() etc
		___________________________________________
		uint16 port			|	|	|	|				<-- needs unique identifier for stdin 
		___________________________________________			int value assigned only once bind accept, or connect called
		struct tcp_connection|	|	|	|
		_____________________________________ _ ___ __

	int port: 	- need unique identifier for stdin
				- int value should only be assigned once bind() accept() or connect() called
				- assignment to port necessary for when receiving/sending tcp packets
					-- when handler calls on us to handle packet, we should know socket_id/tcp_connection
						 it corresponds to based on the tcp packet's destination port matching port in table


	struct tcp_connection:  (file added to git).
		int socket_id;
		tcp_socket_address_t local_addr;		-- it seems a socket is generally defined by 
		tcp_socket_address_t remote_addr;			its pair {(local ip, local port), (remote ip, remote port)}
			where:
				 struct tcp_socket_address{
					uint32_t virt_ip;	<--- what does this mean if listening on all interfaces??????
					uint16_t virt_port;
				};
			// doesn't need to know local ip
				needs to know remote ip for sending to ipnode
		
		handles own sliding window protocol?
		handles own state machine?
		
		has wrapper functions for sending packet and receiving packet
		
		to send a packet:
			sliding window protocol and the state machine need to somehow work in coordination
			the state machine has to be able to decide whether or not sending given packet in given way (connect() send())
				is legal
			-- how should this be done?
			- lastly the packet should go through a helper method that just wraps it appropriately in tcp_utils

start():

	create queue to_send	  --- tcp data for ip to send
	create queue to_read   --- tcp data that ip pushes on to queue for tcp to handle
	create queue stdin_commands --- some user commands to tcp_node driver need to be handled by ip_node
										like interfaces, up, down, etc
									enqueue and dequeues char* data types that are the buffered commands


	alex created ip_thread_data struct to pass in following arguments to start:
		struct ip_thread_data{
			ip_node_t ip_node;
			bqueue_t to_send;
			bqueue_t to_read;  
			bqueue_t stdin_commands;
		};
			// data type that to_send and to_read queues will store (ie queue and dequeue) -- need vip's associated with packet
				typedef struct tcp_packet_data{
					uint32_t local_virt_ip;
					uint32_t remote_virt_ip;
					char packet[MTU];
					int packet_size;  //size of packet in bytes
				} tcp_packet_data_t;

***
tcp_node runs ip_node in 3 separate threads that handle different responsibilities and queues:
	ip_link_interface_thread:  reads off link interfaces (current select() loop) and throws packets for tcp to handle into to_read
	ip_send_thread: calls p_thread_cond_wait(&to_send) and sends things loaded on to queue
	ip_command_thread: calls p_thread_cond_wait(&stdin_commands) and handles ip commands loaded on to queue
	
	
checksum:
	for this to work: only pass in tcp_connection_get_local_ip/remote_ip
	only set remote/local_ip when first establish connection

			
NEIL:
	write tcp checksum -- FIX
	int recv_window_validate_seqnum

ALEX:

	TODO
	
	DEAL WITH ESTABLISHED STATE AND TEAR-DOWN	
	fix states.c to deal with corner conditions

SET BACK TO 1024: in tcp_node.h:	
/* set artificially low right now so we can make sure have no segfaults if ever reach limit */
#define MAX_FILE_DESCRIPTORS 5 // per process limit commonly set to 1024 on mac and linux machines
	
alex's questions for neil:

	to replicate Alex's segfaults that happen at plainlist_remove:
		set MAX_FILE_DESCRIPTORS (found in tcp_node.h) to something very low like 5.
		open up a bunch of accepting connections.  try to connect past MAX_FILE_DESCRIPTORS limit

alex's questions for tas:
	
alex's checksum changes:

	
	
TODO: TO HANDLE:

	put user time outs into the closing protocol
	
	recvfile
	
	simultaneous open thing
	
	deal with an interface going down

	receiveRST when in ESTABLISHED state	
	handle all closed by RST cases
	
	I don't think we're properly handling active close in that we should wait for all data to be 
	'segmented' before sending fin
	
	To enhance efficiency:
		do we want to stop that infinite thread loop in transition TIME_WAIT_to_CLOSED
			- like we could set connection->running = 0 and just restart thread if connect/listen called
	
ssh key: ssh-add it really isn't that hard
		

	
	
	
	
	
	
